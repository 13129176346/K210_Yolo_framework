BATCH_SIZE_REF: &BATCH_SIZE_REF 64
WIDTH_REF: &WIDTH_REF 112

mode: train
model:
  name: feacrec
  helper: FcaeRecHelper
  helper_kwarg:
    image_ann: data/ms1m_img_ann.npy
    in_hw:
      - *WIDTH_REF
      - *WIDTH_REF
    embedding_size: 128
    use_softmax: true
  network: mbv1_facerec
  network_kwarg:
    input_shape:
      - *WIDTH_REF
      - *WIDTH_REF
      - 3
    class_num: 85742
    embedding_size: 128
    depth_multiplier: 0.5
    loss: 'asoftmax'
  loss: Sparse_AsoftmaxLoss
  loss_kwarg:
    batch_size: *BATCH_SIZE_REF
    scale: 30
    margin: 0.35
train:
  graph_optimizer: true
  graph_optimizer_kwarg: 
    layout_optimizer: true
    remapping: true
    shape_optimization: true
    loop_optimization: true
    constant_folding: true
    function_optimization: true
    scoped_allocator_optimization: true
    layout_optimizer: true
  augmenter: false
  batch_size: *BATCH_SIZE_REF
  pre_ckpt: null
  rand_seed: 10101
  epochs: 30
  log_dir: log
  sub_log_dir: default_facerec_asoftmax_exp
  debug: false
  verbose: 1
  vali_step_factor: 0.3
  optimizer: Adam
  optimizer_kwarg:
    learning_rate: 0.001
    beta_1: 0.9
    beta_2: 0.999
    amsgrad: false
  Lookahead: true
  Lookahead_kwarg:
    k: 5
    alpha: 0.5
  callbacks:
    - name: EarlyStopping
      kwarg:
        monitor: val_loss
        min_delta: 0
        patience: 4
        verbose: 0
        mode: auto
        baseline: null
        restore_best_weights: false
    - name: ModelCheckpoint
      kwarg:
        monitor: val_loss
        verbose: 0
        save_best_only: true
        save_weights_only: false
        mode: auto
        save_freq: epoch
        load_weights_on_restart: false
prune:
  is_prune: false
  init_sparsity: 0.5
  final_sparsity: 0.9
  end_epoch: 5
  frequency: 100
inference:
  infer_fn: pfld_infer
  infer_fn_kwarg:
    radius: 1
